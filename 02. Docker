Ch 02.  도커를 이용한 컨테이너 관리

ap-northeast-2
json


01. 도커 이미지와 컨테이너
client - server
client는 console
server에는 docker engine 있음(image와 container 관리)

build, pull 등으로 image를 관리함
이미지 저장소(registry) - DockerHub 등

Image
컨테이너를 생성할 때 필요한 요소로 컨테이너의 목적에 맞는 바이너리와 의존성이 설치되어 있음, 여러 개의 계층으로 된 바이너리 파일로 존재

Container
이미지를 실행한 것
호스트와 다른 컨테이너로부터 격리된 시스템 자원과 네트워크를 사용하는 프로세스
이미지는 읽기 전용으로 사용하여 변경사항은 컨테이너 계층에 저장
컨테이너에서 무엇을 하든 이미지는 ㅇㅇ향 받지 않음

이미지와 컨테이너는 1:N 관계

Docker File -> BUILD -> Docker Image -> Run -> Docker Container

이미지는 컨테이너에 대한 명세 -> 컨테이너는 그것을 통해 실행된 프로세스

Repository Name/Image Name:Image Tag - fastcampus/nginx:1.21
Repository Name/Image Name - fastcampus/nginx
Image Name:Image Tag - nginx:latest
Image Name - nginx
저장소 이름 생략 가능 - 생략하면 도커 허브를 기본 저장소로 인식
태그 생략 가능 - 최신 리비전을 가리키는 latest로 인식

Image Repository
도커 이미지를 관리하오 공유하기 위한 서버 어플리케이션
public - docker hub QUAY
private -  AWS ECR, docker registry를 비공개 식으로 사용



02. 도커 컨테이너 다루기 컨테이너 라이프 사이클
docker run (create+start -> running)
docker create -> docker staret (container 먼저 만들고 실행) -> running

docker run \
-i \  호스트의 표준 입력을 컨테이너와 연결 (interactive) (키보드 입력 호스트-컨테이너 통하게)
-t \  TTY 할당 (터미널 이용 가능하게)
(컨테이너에  shell 실행할 때 -it 같이 씀)

--rm \  컨테이너 실행 종료 후 자동 삭제

-d \  백그라운드 모드로 실행 (detached) (컨테이너가 백그라운드에서 데몬 형태로 실행됨)

--name \  컨테이너 이름 지정

-p 80:80 \ 호스트-컨테이너 간 포트 바인딩

-v /opt/example:/example \ 호스트-컨테이너 간 볼륨 바인딩 (컨테이너가 호스트의 파일 시스템에 접근 가능한 상태)

fastcampus/hello-world:latest \ 실행할 이미지

my-command 컨테이너 내에서 실행할 명령어 (없으면, 기본적으로 실행할 이미지의 기본 명령어가 실행됨)

docker run ubuntu:focal
기본 bash 명령 실행하고 바로 종료됨(백그라운드 형태임, 그리고 입력 없으니까)

docker run -it ubuntu:focal
컨테이너 내부에 bash shell로 뜸
exit 하면 종료됨
ctrl + p,q 빠녀 나오는데 컨테이너는 계속 실행 상태임

docker run nginx
docker run -d nginx

docker run -d --name my-nginx nginx

docker run -d -p 80:80 nginx (host 80과 container 80 바인딩)

curl localhost:80

docker run ubuntu:focal id

docker run --rm ubuntu:focal id

docker run -it ubuntu:focal 하면 shell이 뜨고 docker run -it -d ubuntu:focal 하면 shell이 뜨지 않지만 ps 상태임

docker inspect (상세정보임) - 문제 생겼을 때 많이 쓰는 명령어임

docker pause
docker unpause

docker stop (SIGTERM 시그널 전달) 컨테이너 안정적으로 종료
docker kill (SIGKILL 시그널 전달)
터미널1 - docker run nginx
터미널2 - docker stop과 docker kill 사용하여 차이점 보기

docker stop $ (docker ps -a -q)
docker ps -a -q 모든 컨테이너 id가 출력됨 -> 이 결과값을 묶어서 stop 시키는 것임

docker rm
docker rm -f (실행 중 컨테이너도 삭제 가능, 아니면 stop시키고 삭제하던가)
docker container prune (중지된 모든 컨테이너 삭제)



03. 도커 컨테이너 다루기: 엔트리포인트와 커맨드
Dockerfile의 엔트리포인트와 커맨드
도커 명령어의 앤트리포인트와 커맨드

docker run ubuntu:focal
cmd는 컨테이너가 실행할 때 수행할 명령어가 됨 - bash실행함

docker inspect <container id>
기본 bash 커맨드가 동작함 (inspect - config란에 cmd는 bash, entrypoint는 null임)

docker run --entrypoint sh -it ubuntu:focal
엔트리 포인트는 도커 컨테이너가 실행할 때 고정적으로 실행되는 스트립트 혹은 명령어임, 생략하면 기본 cmd수행

docker run --entrypoint echo ubuntu:focal hello world
(순서가 entrypoint image text임)
(inspect해보면 이때 cmd는 인자 2개는 entrypoint에 지정된 명령어의 인자 값이 됨)
docker ps -a (COMMAND가 echo hello world 로 합쳐진 것을 볼 수 있음)

docker run ubuntu:focal sh
(이러면 command로 sh실행함, entrypoint 없이)


04. 도커 컨테이너 다루기: 환경변수
컨테이너 실행시 변수 주입하는 방법
변수 설정에 따라 원하는 방식대로 다르게 컨테이너 동작키실 수 있음

두 가지임 (-e = --env임)
--env(= -e) list (Set enviroment variables) 방법
docker run -it -e MY_HOST=fastcampus.com ubuntu:focal
env
echo $MY_HOST
docker inspect해서 config-env 부분도 볼 것


--env-file list (Read in a file of enviroment variables) 방법

sample.env 만들기
cat > sample.env
MY_HOST=helloworld.com
MY_VAR=123
MY_VAR2=456
(ctrl + d)

docker run -it --env-file ./sample.env ubuntu:focal env


05. 도커 컨테이너 다루기: 명령어 실행
실행 중인 컨테이너에 명령어를 실행하는 명령어
주로 이슈 해결을 위해 많이 사용함

docker exec [container] [command]

docker run -d --name my-nginx nginx
docker exec -it my-nginx bash
docker exec my-nginx env

ls -l /etc/nginx
nginx 이슈 해결하기 위해 설정을 보거나 접근한다든지


06. 도커 컨테이너 다루기: 네트워크
docker0: 172.17.42.1
도커 엔진에 의해 기본 생성되는 브릿지 네트워크
도커 컨테이너를 실행할 떄 사용할 네트워크 지정하지 않으면 디폴트로 사용
veth와 호스트 eth0 간 다리 역할
 
eth0: 192.168.1.22
호스트에서 사용하고 있는 기본 네트워크
(로컬이나 ec2의 private ip)

veth: virtual eth

그리고 컨테이너 실행하면 2가지 장치 설치되어 있음
l0 - (127.0.0.1 이라는 루프백 네트워크, local network, localhost)
eth0 - 172.17.0.2

그리고 eth에 대응되는 veth라는 장치 생성함 (veth5998947)

컨테이너와 호스트 네트워크 간의 연결

docker run -p [HOST IP:Port]:[CONTAINER PORT] [container]

nginx 컨테이너의 80번 포트를 호스트 모든 IP의 80번 포트와 연결하여 실행
docker run -d -p 80:80 nginx
(0.0.0.0:80->80/tcp)
curl localhost:80
curl 192.168.219.103:80
(맥은 ifconfig | grep inet -> 192.168.219.103)

curl <public ip>:80 (ec2경우 ec2metadata보면 public ip나옴)
(ec2metadata 없으면 apt install cloud-utils)


nginx 컨테이너 80번 포트를 호스트 127.0.0.1 IP의 80번 포트와 연결하여 실행
docker run -d -p 127.0.0.1:80:80 nginx

curl localhost:80
(public private는 다 접속 안됨)

nginx 컨테이너의 80번 포트를 호스트의 사용 가능한 포트와 연결하여 실행 (랜덤)
(위에 실습은 지우고)
docker run -d -p 80 nginx
(0.0.0.0:52615->80/tcp)

curl localhost:52615

참고사항
IP 주소 127.0.0.1은 localhost 또는 루프백 주소 라고하는 특수 목적의 IPv4 주소 입니다. 모든 컴퓨터는이 주소를 자체 주소로 사용하지만 실제 IP 주소처럼 다른 장치와 통신 할 수는 없습니다.
라우터 및 기타 네트워크 장치와 통신 할 수 있도록 컴퓨터에 192.168.1.115 개인 IP 주소가 할당되어있을 수 있습니다. 그러나이 "127.0.0.1"주소는 여전히 "이 컴퓨터"또는 현재 사용중인 주소임을 의미합니다.
루프백 주소는 사용중인 컴퓨터에서만 사용되며 특별한 경우에만 사용됩니다. 이것은 다른 네트워크 장치간에 파일을 전송하는 데 사용되는 일반 IP 주소와는 다릅니다.
예를 들어, 컴퓨터에서 실행중인 웹 서버는 127.0.0.1을 가리킬 수 있으므로 페이지를 배포하기 전에 로컬에서 실행하고 테스트 할 수 있습니다.

Expose vs Publish
expose 옵션은 그저 문서화 용도
publish 옵션은 실제 포트를 바인딩

docker run -d --expose 80 nginx
(맵핑 표시인 -> 가 없고 80/tcp 이렇게만 나옴)
(curl localhost:80 접속 안됨)

docker run -d -p 80 nginx


도커에서 지원하는 네트워크 드라이버
(컨테이너에 네트워크를 공유하는 방법)

docker network ls
docker -> Container Network Model -> Native Drivers -> Bridge, Host, None, Overlay
 								-> Remote Drivers -> 3rd-Party Pliugins (설치해서 사용)

Single Host Netrowking에서 동작하는 드라이버
bridge - docker0(default) or user dfined(직접 새로운 bridge 네트워크 생성해서 사용)
host
none

Multi Host Networking에서 동작하는 드라이버
overlay - 각각의 서버에 있는 컨테이너들을 연결시키는 가상의 네트워크
(자체 docker swarm 등의 오케스트레이션 시스템에서 많이 사용)

none 살펴보기
컨테이너가 네트워크 기능이 필요 없을 때나 커스텀 네트워킹을 사용해야 할 때

docker run -i -t --net none ubuntu:focal
apt update 등 안 먹음
local에서 docker inspect <container id>의 IPAddress가 null임


host 살펴보기
docker가 제공하는 가상 네트워크가 아닌 직접 host network에 붙어 사용하는 것임
port binding 안해도 바로 접속 가능함

docker run -d --network=host grafana/grafana (grafana는 기본 3000포트 사용함)
docker ps (PORTS 목록 안보임)
curl localhost:3000 (ec2 vm에서는 되는데,아마 docker desktop 설치된 내 mac에서는 안되는 것 같음)
docker inspect <container id>
(IPAdress 따로 없음, Config-Hostname 있음)


bridge 살펴보기
docker network create --driver=bridge fastcampus

docker run -d --network=fastcampus --net-alias=hello nginx
docker run -d --network=fastcampus --net-alias=grafana grafana/grafana
(--netalias는 브릿지 네트워크에만 사용 가능한 옵션으로 브릿지 네트워크 안에서 hello라는 도메인 네임으로 컨테이너 ip를 서치할 수 있도록 내부 도메인에 저장을 해주는 옵션)

docker network ls
docker ps

docker exec -it <grafana container id> bash
cd /tmp
wget hello
cat index.html
  
docker exec -it <nginx container id> bash
curl grafana:3000

ifconfig
(mac local이라 다른데 ec2에서 후에 체크해 보면)
컨네이터 갯수만큼 - veth~

ens5 - 호스트의 eth, ec2?
en - mac?

utun - mac의 virtual interface

bridge - mac?
br - ec2?



07. 도커 컨테이너 다루기- 볼륨

도커 레이어 아키텍쳐
Container Layer
Image Layers

dockerfile -> docker build -t app .
docker image가 빌드 된다
layer구조로 돼있다

Layer 5: Update Entrypoint
Layer 4: Source code
Layer 3: Install in pip packages
Layer 2: Changes in apt packages
Layer 1: Base Ubuntu Layer
변경 사항이 생기면 해당 Layer만 변경하면 된다 (branch가 따지면서)
(source code변경시 new layrt 4, 5가 생김)

docker run app

Continer Layer (Read Write) (Layer 6)
기존 Image Layers (Read Only) (Layer 1~5)

컨테이너 종요시 container layer는 삭제가 되기에 볼륨의 필요성이 생김

볼륨 사용 - 3가지 방식
호스트 볼륨
호스트 운영체제 디렉토리를 컨테이너의 특정 경로에 마운트
-v [호스트 경로]:[컨테이너 경로]

docker run -d --name nginx -v /opt/html:/usr/share/nginx/html nginx
docker exec -it <container id> bash

cat > hello
hello world!

doker rm -f <container-id>

볼륨을 사용하지 않으면 데이터 삭제됨을 알 수 있다

fastcampus-devops/3-docker-kubernetes/2-docker-volume 디렉토리로 이동

cat host-volume.sh의 내용
#!/usr/bin/env sh

docker run \
  -d \
  -v $(pwd)/html:/usr/share/nginx/html \
  -p 80:80 \
  nginx

$(pwd) 명령어는 현재 working directory 경로임

html 폴더에는 index.html 있음

docker run -d -v ~/fastcampus-devops/3-docker-kubernetes/2-docker-volume/html:/usr/share/nginx/html -p 80:80 nginx
curl localhost
docker exec -it <container id> bash
cat /usr/share/nginx/html/index.html


cat > /usr/share/nginx/html/hello
Hello World!
exit
html 폴더에 hello 파일 생성되어 있음


볼륨 컨테이너
Dada-only Container를 하나 더 생성하는 것임

예시
docker run -d --name mu-volume -it -v /opt/html/:/usr/share/nginx/html ubuntu:focal
docker run -d --name nginx --volumes-from my-volume nginx

실습
docker run -d -it -v ~/fastcampus-devops/3-docker-kubernetes/2-docker-volume/html:/usr/share/nginx/html --name web-volume ubuntu:focal

docker run -d --name fastcampus-nginx --volumes-from web-volume -p 80:80 nginx

docker run -d --name fastcampus-nginx2 --volumes-from web-volume -p 8080:80 nginx

curl localhost:80
curl localhost:8080

docker inspect fastcampus-nginx의 volume mounts 정보 확인해 보기
docker inspect fastcampus-nginx2의 volume mounts 정보 확인해 보기

docker exec -it <container-id> bash


도커 볼륨 (많이 사용하는 편임)
도커가 제공하는 볼륨 관리 기능을 활용하여 데이터를 보존함
기본적으로/var/lib/docker/volumes/${volume-name}/_data에 데이터가 저장됨

docker volume create --name db
docker volume ls
docker run -d --name fastcampus-mysql \
-e MYSQL_DATABASE=fastcampus \
-e MYSQL_ROOT_PASSWORD=fastcampus \
-v db:/var/lib/mysql \
-p 3306:3306 \
mysql:5.7

(mysql은 2가지 환경 변수 설정해 줘야 정상 기동된다 - 데이터베이스 이름과 루트 계정 패스워드)

docker volume inspect db

sudo ls -l /var/lib/docker/volumes/db/_data
(linux 환경이라면 되는데 windows나 mac은 다른 방법 써야 함)
(hypervisor, 즉 vm으로 linux를 구동하고 그 위에 docker engine을 구동히기 떄문에 경로가 틀림)


읽기 전용으로 볼륨을 연결하는 방법

예시
docker run -d --name nginx -v web-volume:/usr/share/nginx/html:ro nginx
(ro옵션임)

실습
docker run -d -v ~/fastcampus-devops/3-docker-kubernetes/2-docker-volume/html:/usr/share/nginx/html:ro -p 80:80 --name ro-nginx nginx
docker exec ro-nginx touch /usr/share/nginx/html/test



08. 도커 컨테이너 다루기: 로그

STDOUT / STDERR
APP Container가 stdout이나 stderr을 보내면 logging driver가 처리함 (드라이버는 다양함, json-file 등)

docker logs [container]

docker logs --tail 10 [container] 마지막 로그 10줄 확인

docker logs -f [container] 실시간 로그 스트림 확인

docker logs -f -t [container] 로그마다 타임스탬프 표시
(그런데 타임스탬프는 기본으로 찍혀 나오는 것 같음 - 중복됨)

docker run -d nginx
docker logs
docker logs --tail 5
docker logs -f -t 

cat /var/lib/docker/containers/${CONTAINER_ID} /${CONTAINER_ID}-json.log

sudo ls -l /var/lib/dokcer~~~~~~


로그 용량 제한하기
실습이라 컨테이너 단위로 로그 용량 제한 하겠지만, 원래 도커 엔진에서 기본 설정한다(운영환경에서 필수 설정)

docker run -d --log-driver=json-file --log-opt max-size=3m --log-opt max-file=5

* Ubuntu: /var/lib/docker/
* Fedora: /var/lib/docker/
* Debian: /var/lib/docker/
* Windows: C:\ProgramData\DockerDesktop, C:\Program Files\Docker\Docker
* MacOS: ~/Library/Containers/com.docker.docker/Data/vms/0/

macOS에서는 container runtime이 다음과 같이 LinuxKit 위에서 실행된다
containerd
LinuxKit
Hyperkit
macOS

nc -U ~/Library/Containers/com.docker.docker/Data/debug-shell.sock
cat /var/lib/docker/containers/${CONTAINER_ID} /${CONTAINER_ID}-json.log

(ppt 참고)
json-file이라는 드라이버 ->files로 호스트 운영체제에 저장 -> log agent 설치(filebeat, fliuentd 등) -> 자신의 로그 시스템에 저장(elasticsearch, spluik, graylog, aws cloudwatch 등) -> 이러면 전체 컨테이너 로그를 중앙에서 관리 가능하다



09. 도커 컨테이너 다루기: 이미지 빌드
도커 이미지 구조
Layer A B C가진 ubuntu image
Layer A B C 위에 nginx가 쌓인 nginx image
Layer ABC + nginx 위에  web app source가 쌓인 web app

Docker Container
위의 web app image를 가지고 컨테이너로 실행 (read only)
컨테이너 생성할 때마다, 그 위에 read, write 가능한 컨테이너 레이어가 생성됨

docker image inspect nginx

RootFS의 Type이 layers임
sha256:~~~
sha256:~~~s
sha256:~~~

레이어들이 sha256 캐쉬 함수를 통해 캐쉬 값으로 표현되어 있음


Dockerfile 없이 이미지 생성
기존 컨테이너를 기반으로 새 이미지를 생성할 수 있음
docker commit  [OPTION] CONTAINER [REPOSITORY[:TAG]]

실습
docker run -it --name my_ubuntu ubuntu:focal
cat > my_file
Hello Fastcampus!

ctrl+ p, q (컨테이너 종료 안되게)

docker commit -a fastcampus -m “Add my_file” my_ubuntu my-ubuntu:v1
-a 누가 이 변경점을 만드는지 히스토리로 만들 수 있음 (fastcampus)
-m commit메시지임 (Add my_file)

docker images inspect ubuntu:focal 
docker images inspect my-ubuntu
(sha256이 각각 1, 2개인데, 최신에 쌓인게 밑줄로 입력됨)

docker run -it my_ubuntu:v1
(my_file 존재함)


Dockerfile 이용하여 이미지 생성
FROM
RUN
WORKDIR
COPY
RUN
CMD

docker build [OPTIONS] PATH

docker build -t my_app:v1 ./
(-t = tag)

docker build -t my_app:v1 -f example/MyDockerfile ./
(-f dockerfile의 경로임)
(차이점은 위에는 현재 경로를 기반으로 빌드하고, dockerfile도 현재 디렉토리에 있음)
(아래는 현재 경로를 기반으로 빌드하는데, dockerfile 위치는 다른 곳임)

3-dockerfile/app 경로 참고
app install tree
tree
tree -L 2

docker build -t my-app:v1 ./
(build context를 docker daemon에 보냄)

6지시어에 6step

마지막 지시어에 수정 할 경우,
다는 아니지만, docker daemon이 판단했을 때 레이어 중에 동일한 재사용 레이어는 캐싱한다

빌드 컨텍스트
도커 빌드 명령 수행 시 현재 디렉토리Current Working Directory)를 빌드 컨텍스트(build context)라고 함
Dockerfile로부터 이미지 빌드에 필요한 정보를 도커 데몬에게 전달하기 위한 목적임

.dockerignore
특정 디렉토리 혹은 파일 목록을 빌드 컨텍스트에서 제외하기 위한 목적임
(해당 디렉토리의 정보가 크면, build하는 시간이 길어진다)
(제외하고 빌드 컨텍스트를 도커 데몬에 보내기 때문에 이미지에 포함되지 않아야 하는 파일들을 제외시킬 수 있음)
(.gitignore와 동일한 문법을 가지고 있음)



10. 도커 이미지 다루기- Dockerfile 문법
https://docs.docker.com/engine/reference/builder/

# Comment (주석)

지시어 인자값 구조
(INSTRUCTION arguments)

환경변수 전달법 2가지
ENV FOO=/bar -> image buildtime과 container runtime에 환경변수값 전달함
WORKDIR ${FOO} -> 중괄호는 무슨 의미임??
ADD . $FOO
COPY \$FOO /quux
(여기서 환경변수는 컨테이너의 환경변수임!)

ARG로 환경변수 정의
FROM busybox
ARG user1=someuser
ARG buildno-1

or

docker build --build-arg CONT_IMG_VER=v2.0.1 .

참고1
FROM busybox
USER ${user:-some_user}
ARG user
USER $user

Scope(변수 영역)라는 개념 추후 공부 요망 - ARG가 먼저 정의되기 전에 USER가 있기에 적용 안되고 기본값 some_user만 적용됨
그럼 docker build --build-arg user=what_user .
(의미가 없어짐)

참고2
ENV 지시어가 더 상위임 -> ARG 덮어씀
FROM ubuntu
ARG CONT_IMG_VER
ENV CONT_IMG_VER=v1.0.0
RUN echo $CONT_IMG_VER

docker build --build-arg CONT_IMG_VER=2.0.1 .
(RUN 지시어는 v1.0.0을 사용할 것임)

/3-docker-kubernetes/3-dockfile/nodejs-server/
dockerfile 보면

#
# nodejs-server
#
# build:
#   docker build --force-rm -t nodejs-server .
# run:
#   docker run --rm -it --name nodejs-server nodejs-server
#

FROM node:16  (사용할 베이스 이미지임)
LABEL maintainer="FastCampus Park <fastcampus@fastcampus.com>" (이미지의 메타데이터)
LABEL description="Simple server with Node.js" 

# Create app directory
WORKDIR /app - 빌드하는 이미지 내에서 working directory로 이동, 설정하는 것임

# Install app dependencies
# A wildcard is used to ensure both package.json AND package-lock.json are copied
# where available (npm@5+)
COPY package*.json ./
(COPY SRC DEST인데 각각 호스트OS 이미지상임, DEST는 위의 /app이 됨)
(이 파일만 먼저 뺀 이유는 package설치 내용을 따로 레이어 하나로 만들기 위함임)

RUN npm install (package*.json을 읽어와서 package 설치함)
# If you are building your code for production
# RUN npm ci --only=production

# Bundle app source
COPY . .
(소스코드 변경사항을 위의 package 레이어 뒤에 실행하려고)

EXPOSE 8080 (해당 포트 publishing이 아니라 문서화하는 것뿐 - 앞에서도 했음)
CMD [ "node", "server.js" ] (해당 이미지를 가지고 컨테이너를 실행할 떄 어떤 명령어를 실행할 것인가임)

docker run -d -p 8080:8080 nodejs-server

ENTRYPOINT 지시어
command에 앞서 시작 프로그램 지정 가능
배열 형태(execform)
ENTRYPOINT [“executable”, “param1”, “param2”]

문자열 형태(shellform)
ENTRYPOINT command param1 param2
 

ADD 지시어
COPY 비슷한데 path directory로 url을 받을 수 있음
그러나 url로 받으면 소스값 변경 여부 체크 어려워서 그냥 COPY 씀

USER 지시어
도커 컨테이너가 사용하게 될 기본 사용자나 그룹 지정 가능 (보안 고려할 때 반드시 사용)


11. 도커 이미지 다루기: 이미지 압축파일로 저장 및 불러오기
인터넷이 안되는 환경에서 활용
온라인 상에 올리지 않고 서버에 올리거나 전달할 때

docker save -o [OUTPUT-FILE] IMAGE
docker save -o ubuntu_focal.tar ubuntu:focal

file ubuntu_focal.tar

docker load -i [INPUT-FILE] (압축파일에서 이미지 불러옴)
docker load -i ubuntu_focal.tar
(원본과 동일한 image id임)


12. 도커 이미지 다루기: 도커허브 저장소 이용
이미지 관리, 공유 도와주는 서비스

https://hub.docker.com

settings - security - access tokens
fastcampus
dckr_pat_BocaQ3T16tUbRTTp0FVoyX055Ho

docker login -u #########

/home/ubuntu/.docker/config.json.

my-nginx라는 private repository 만들 것

push 방식 두 가지임
docker tag local-image:tagname new-repo:tagname (어떤 레포지토리에 올릴지, 이미지 이름은 뭔지)
docker push new-repo:tagname

docker tag nginx:latest #########/my-nginx:v1.0.0

docker push #########/my-nginx:v1.0.0

docker pull #########/my-nginx:v1.0.0



13. 도커 이미지 다루기: AWS ECR 저장소 이용

aws sts get-caller-identity

aws configure

aws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin ############.dkr.ecr.ap-northeast-2.amazonaws.com
(aws ecr 로그인 정보를 docker loing으로 전달하는 형식임)

docker build -t my-nginx .
docker tag my-nginx:latest ############.dkr.ecr.ap-northeast-2.amazonaws.com/my-nginx:latest
docker push ############.dkr.ecr.ap-northeast-2.amazonaws.com/my-nginx:latest

docker pull ############.dkr.ecr.ap-northeast-2.amazonaws.com/my-nginx:latest


14. 도커 이미지 다루기: 이미지 경량화 전략

꼭 필요한 패키지 및 파일만 추가 - 리눅스처럼 필요한 모든 패키지를 설치하지 말 것
컨테이너 레이어 수 줄이기 (=지시어 수 줄이기)
경량 베이스 이미지 선택
멀티 스테이지 빌드 사용



컨테이너 레이어 수 줄이기 (=지시어 수 줄이기)
3-docker-kubernetes/3-dockerfile/slacktee/dockerfile

vi slacktee/dockerfile
하나의 RUN 지시어에 명령 몰아줌
도커 이미지 상에서는 패키지 캐시가 필요하지 않기에 그것도 적용(--no-cache 옵션과 cache 삭제)

#
# slacktee
#
# build:
#   docker build --force-rm -t slacktee .
# run:
#   docker run --rm -it --name slacktee slacktee
#

FROM alpine:3.14
LABEL maintainer="FastCampus Park <fastcampus@fastcampus.com>"
LABEL description="Simple utility to send slack message easily."

# Install needed packages
RUN \
  apk add --no-cache bash curl git && \
  git clone https://github.com/course-hero/slacktee /slacktee && \
  apk del --no-cache git
RUN chmod 755 /slacktee/slacktee.sh

# Run
WORKDIR /slacktee
ENTRYPOINT ["/bin/bash", "-c", "./slacktee.sh"]



경량 베이스 이미지 선택

debian의 slim 계열
alpine이라는 리눅스 디스트리뷰섵
stretch - 파일 시스템만 존재함, 컴파일 언어에서 사용

3-docker-kubernetes/3-dockerfile/nodejs-server/여러 도커 파일들
909MB 크기임 (node 16 버전 자체가 905MB임)

node 16-slim
docker build --force-rm -t nodejs-server:slim -f Dockerfile.slim .

node 16-alpine (도커 컨테이너를 위해 만들어진 리눅스 배포판)
docker build --force-rm -t nodejs-server:alpine -f Dockerfile.alpine .



멀티 스테이지 빌드 사용
3-docker-kubernetes/3-dockerfile/nodejs-server/Dockerfile.alpine-multi

FROM 지시어에서 AS 사용하는 문법 이용
(FROM 블록을 여러 개 정의함, base에 정의 된 layer를 동일하게 사용하겠다는 것임)

#
# nodejs-server
#
# build:
#   docker build --force-rm -t nodejs-server .
# run:
#   docker run --rm -it --name nodejs-server nodejs-server
#

FROM node:16-alpine AS base
LABEL maintainer="FastCampus Park <fastcampus@fastcampus.com>"
LABEL description="Simple server with Node.js"

# Create app directory
WORKDIR /app

# Install app dependencies
# A wildcard is used to ensure both package.json AND package-lock.json are copied
# where available (npm@5+)
COPY package*.json ./


FROM base AS build
RUN npm install
# If you are building your code for production
# RUN npm ci --only=production


FROM base AS release
COPY --from=build /app/node_modules ./node_modules
# Bundle app source
COPY . .

EXPOSE 8080
CMD [ "node", "server.js" ]


docker build --force-rm -t nodejs-server:alpine-multi -f Dockerfile.alpine-multi .



15. 도커를 이용한 컨테이너 관리: 도커 데몬 디버깅
docker system info (Display system-wide information)

docker system events (Get real time events from the server)
(=docker events, alias되어 있음)
terminal1 - docker system events
terminal2 - docker run --name my-nginx nginx:latest

우분투는 다음 명령어로도 도커 이벤트 확인 가능함
journalctl -u docker


docker system df (Show docker dick usage)
RECLAIMABLE - docker가 회수할 수 있는 자원의 양

docker system df -v (자세히)


docker system prune (Remove unused data)
all stopped containers
all networks not used by at least one container
all dangling images
all dangling build cache

docker stats
각각의 컨테이너가 어떻게 리소스 자원 사용하는d지

 


16. 도커 컴포즈: 명시적으로 여러 컨테이너 관리하기
단일 서버에서 여러 컨테이너를 프로텍트 단위로 묶어서 관리
docker-compose.yml YAML 파일을 통해 명시적 관리

프로젝트 단위로 도커 네트워크와 볼륨 관리
프로젝트 내 서비스 간 의존성 정의 가능 (service2는 service1 실행한 뒤에 실행해야 해)
프로젝트 내 서비스 디스커버리 자동화 (--net-alias로 이름 줘서 디스커버리 가능하게 한것 기억해 보라)
손 쉬운 컨테이너 수평 확장

Project (=YAML 파일 한 개)
도커 컴포즈에서 다루는 워크스페이스 단위
함께 관리하는 서비스 컨테이너의 묶음
프로젝트 단위로 기본 도커 네트워크가 생성 됨

Service
도커 컴포즈에서 컨테이너를 관리하기 위한 단위
scale을 통해 서비스 컨테이너의 수 확장 가능

Cantainer
서비스틑 통해 컨테이너 관리


도커 컴포즈는 도커컴포즈파일에 미리 여러 컨테이너를 정의해두고 컨테이너들의 실행 순서 DB연결 등을 정할 수 있다. 
간단하게 말해서 도커 컴포즈란 도구는 노가다 과정을 줄여주는 것이다

docker-compose는 내가 시작할 때 container를 선언해주는 것이다. node나, cluster개념은 없다.
그런데 둘다 configuration files (Yaml)을 만들수 있다. 아마 이 이유 때문에 둘의 관계에 혼란이 오게 만들어 주는 것 같다.
Docker Compose는 오케스트레이션없이 다중 컨테이너 Docker 응용 프로그램을 정의하고 실행하기위한 도구입니다.
Kubernetes에는 pod이란 개념이 있는데 그것은 여러 컨테이너들을 가지고 있고, 사용 가능한 노드 사이의 분배 개념(클러스트링) 해준다.

docker-compose.yml
최상위 옵션 4가지 - version, services, networks, volumes

version
최신 버전 사용 권장
도커 엔진 및 도커 컴포즈 버전에 따른 호환성 매트릭스 참조할 것 (yaml version 지원 여부)
(https://docs.docker.com/compose/compose-file/compose-file-v3/
버전 3부터 Docker Swarm과 호환 (Swarm 서비스를 docker-compose.yml로 정의 가능)
(여러 서버를 기반으로 스왐 클러스터를 형성하여 컨테이너를 관리하는 컨테이너 오케스트레이션 시스템, 쿠버네티스와 동일 목적으로 만들어졌지만 인기를 끌지 못함)

service
프로젝트 내 구성되는 여러 서비스들

network
구성하지 않아도 default라는 브릿지 네트워크가 기본 생성됨

실습
app.py python파일임

Flash 프레임워크를 이용해서 간단한 웹 애플리케이션 만듦
redis 라이브러리를 사용하여 redis 호스트로 접속

import redis
from flask import Flask

app = Flask(__name__)
cache = redis.Redis(host='redis', port=6379)

def get_hit_count():
    retries = 5
    while True:
        try:
            return cache.incr('hits')
        except redis.exceptions.ConnectionError as exc:
            if retries == 0:
                raise exc
            retries -= 1
            time.sleep(0.5)

@app.route('/')
def hello():
    count = get_hit_count()
    return 'Hello World! I have been seen {} times.\n'.format(count)


dockerfile
FROM python:3.7-alpine
WORKDIR /code
ENV FLASK_APP=app.py
ENV FLASK_RUN_HOST=0.0.0.0
RUN apk add --no-cache gcc musl-dev linux-headers
COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt
EXPOSE 5000
COPY . .
CMD ["flask", "run"]


build는 현재 디렉토리의 dockerfile 찾아서 빌드해라
docker-compose.yml
version: "3.9"
services:
  web:
    build: .
    ports:
    - "5000"
  redis:
    image: "redis:alpine"


docker compose up
(up은 docker run 명령어와 유사함 - create and start containers)

network default 생성 볼 수 있음
프로젝트 이름 없으면 폴더명임, 여기서는 build
Network build_default
Container build-web-1 (프로젝트명-서비스명-컨테이너인덱스, 즉 해당 서비스 상에서의 컨테이서 순서)
Container duild-redis-1

docker compose -p my-project up -d

docker compose ls
docker compose ls -a

프로젝트 내 컨테이너 및 네트워크 종료 및 제거
docker compose down

프로젝트 내 컨테이너, 네트워크 및 볼륨 종료 및 제거
dockdocker compose down -v

서비스 확장
예시
docker-compose up --scale web=3

실습
docker compose -p my-project ps
docker compose -p my-project up --scale web=3

참고
compose yaml에 host port (5000:5000) 지정하면 scale이 불가능하다 (중복, 충돌)
container_name 옵션도 있는데 지정하면 고정되어 scale 불가능해짐
services:
  web:
    container_name: “web”
    build: .
    ports:
    - “5000:5000”

프로젝트 내 명령어들
docker compose logs
docker compose events
docker compose images
docker compose ps 컨테이너 목록
docker compose top 기동중인 컨테이너에서 프로세스를 확인 (table of processess)

docker compose -p my-project logs -f (스트리밍)

terminal1 - docker compose -p my-project events
terminaal2 - docker compose -p my-project up --scale web-1 -d

docker compose -p my-project images


17. 실습: 도커 컴포즈 이용하여 Grafana + MySQL 구성
Grafana
Grafana는 멀티플랫폼 오픈 소스 애널리틱스 및 인터랙티브 시각화 웹 애플리케이션이다. 지원되는 데이터 소스에 연결될 때 웹의 차트, 그래프, 경보를 제공한다

Grafana의 3000번 포트는 호스트의 3000번 포트와 바인딩
Grafana의 설정파일인 grafana.ini는 호스트에서 주입 가능하도록 구성하고 읽기전용 설정
Grafana의 로컬 데이터 저장 경로를 확인하여 도커 볼륨 마운트
Grafana의 플러그인 추가 설치를 위한 환경변수 설정
로그 드라이버 옵션을 통해 로그 로테이팅

+ MySQL
granana.ini를 통해 database 설정을 sqlite에서 MySQL로 변경
MySQL 컨테이너를 docker-compose에 db 서비스로 추가
grafana 서비스가 db 서비스를 database로 연결하도록 구성
MySQL의 로컬 데이터 저장 경로 확인하여 도커 볼륨 마운트

https://grafana.com/docs/grafana/latest/installation/docker/
https://hub.docker.com/_/mysql

3-docker-kubernetes/lab-docker-grafana/grafana-only
(unless-stopped는 always보다 강력한, 서버 재시작시도 기동 보장)
(/var/lib/grafana가 로컬 데이터 저장 경로임)
(sqlite file 형태로 경로에 저장될 것임)

version: '3.9'

services:
  grafana:
    image: grafana/grafana:8.2.2
    restart: unless-stopped
    environment:
      GF_INSTALL_PLUGINS: grafana-clock-panel
    ports:
    - 3000:3000
    volumes:
    - ./files/grafana.ini:/etc/grafana/grafana.ini:ro
    - grafana-data:/var/lib/grafana
    logging:
      driver: "json-file"
      options:
        max-size: "8m"
        max-file: "10"

volumes:
  grafana-data: {}

 도커 볼륨 만드는건가??

참고 - grafana.ini 파일
app_mode = production
instance_name = ${HOSTNAME}

#################################### Server ####################################
[server]
protocol = http
http_addr =
http_port = 3000

#################################### Database ####################################
; [database]
; type = mysql
; host = db:3306
; name = grafana
; user = grafana
; password = grafana


#################################### Logging ##########################
[log]
mode = console
level = info

#################################### Alerting ############################
[alerting]
enabled = true



docker compose up -d
curl localhost:3000
웹브라우저에서 192.168.219.105:3000
웹브라우저에서 localhost:#000
admin
admin

server admin -settings - 여러 정보 있음
database - type -sqlite3

docker compose down -v


3-docker-kubernetes/lab-docker-grafana/grafana-mysql
(mysql-data라는 도커 볼륨 지정)
(depends-on의 db 추가 -> db컨테이너가 먼저 만들어지고 grafana 서비스가 생성될 수 있도록 설정)
(grafana.ini에 ; 주석은 없앴음)
(grafana.ini에 host = db:3306이 있는데 docker composer가 자동으로 service discovery 해주기 때문에 db로 가능 - grafana-mysql의 db service  )


version: '3.9'

services:
  db:
    image: mysql:5.7
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: grafana
      MYSQL_DATABASE: grafana
      MYSQL_USER: grafana
      MYSQL_PASSWORD: grafana
    volumes:
    - mysql-data:/var/lib/mysql
    logging:
      driver: "json-file"
      options:
        max-size: "8m"
        max-file: "10"

  grafana:
    depends_on:
    - db
    image: grafana/grafana:8.2.2
    restart: unless-stopped
    environment:
      GF_INSTALL_PLUGINS: grafana-clock-panel
    ports:
    - 3000:3000
    volumes:
    - ./files/grafana.ini:/etc/grafana/grafana.ini:ro
    - grafana-data:/var/lib/grafana
    logging:
      driver: "json-file"
      options:
        max-size: "8m"
        max-file: "10"

volumes:
  mysql-data: {}
  grafana-data: {}


fastcampus
pwd ####
만들고
docker compose down
docker compose up -d
웹브라우저에서 fastcampus로 로그인 가능함



쿠버네티스의 장점
스케쥴링을 잘해줌
죽어도 스스로 잘 살려줌
확장성
로드 밸런싱
롤아웃/롤백이 자동으로 진행
설정을 관리
