Part.5 운영자를 위한 쿠버네티스

Ch1. Kubernetes 운영 환경 구성
1. Orientation

2. Kubernetes 클러스터 용량 산정
노드당 최대 110개 Pod을 권장
5000 노드 이하 권장 (사실 500노드에소 마스터 노드의 부하 발생함)

최대 Pod 갯수
EKS: 4~737
GKE: 110
AKS: 250

Instance Calculator 사이트 있음
https://learnk8s.io/kubernetes-instance-calculator 

3. 운영 환경 고려 사항
클러스터 모니터링
Metrics-server
Prometheus
Grafana

클러스터 로깅
Elastic (elasticsearch)
(Grafana) Loki

아티팩트 저장소
Helm Chart
퍼블릭이 아닌 자체 저장소도 필요 - HARBOR / CHARTMUSEUM

CI/CD 파이프라인
Spinnaker
ArgoCD

서비스 부하분산, HA 클러스터

보안관리
OAuth, RBAC, Keycloak - 쿠버네티스 인프라 관련련
CVE Scan, Clair, trivy - 어플리케이션 이미지 취약점 점검

4. 운영 환경 설치
온프레미스에 쿠버네티스 배포 툴
kubeadm
KUBESPRAY

워커노드와 컨트롤플레인(=마스터노드?)

온프레미스용 상용 쿠버네티스 플랫폼도 있음
OPENSHIFT (redhat)
VMware Tanzu
RANCHER

온플레미스 구축 시, 관리 포인트
- Etcd
클러스터 가용성, Etcd 클러스터 관리 필요
(리소스에 대한 모든 리소스 정보가 저장,
키밸류 저장 시스템임,
클러스터로 구성됨)

- Load balancing
- 고가용성
- 오토 스케일
- 네트워크
- 스토리지
- 업그레이드
- 모니터링
데이터독, 프로메테우스, 그라파나

5. 운영 환경 유저 관리
운영환경 - 네임스페이스마다 다른 권한
(Administrator, Developer, Operator, Tester, Project Owner...)
Authentication / Authorization (인증과 인가, 권한부여)

개발환경 -  Administrator

Service Account, SA) vs (일반 유저)
쿠버네티스 API로 관리되는 유저 리소스
특정 네임스페이스에 종속
Kube-apiserver
(내외부에 쿠버네티스 리소스를 제어할 수 있는 API 제공
노드 혹은 Pod에 접근할 수 있는 proxy 역할 수행하기도 함)

어드바이저의 인증 수단 (Authentication)
X.509 인증서를 활용한 TLS 인증
- 인증서과 개인키 만들어 api서버에 날림- 검증 뒤 인증서 안의 user 정보 인식
- 개인키로 -> rootCA인증서와 rrotCA개인키를 통해 서명이 된 인증서 만듦(api에서 사용할 수 있는 인증서 - api에서 rootCA인증서를 가지고 있기 때문에 가능) 
- 개인키는 누구나 만들 수 있지만, 이 개인기를 통해 인증서를 만들 때는,  해당 쿠버네티스에서 만든 rootCA인증서가 필요한 것임

Http인증을 활용한 사용자 인증
- Head의 token과 token auth file의 token이 같은지로 검증
- token,username,uid(gd) (csv파일 형식임)

인증 프록시를 활용한 대리 인증
- kube-apiserver 대신 요청을 받고 api서버에 전달함 (중개, 통로 역할)
- -- requestheader 사용
- Kube-api서버 추상화 (api서버 주소가 바껴도 상관없음)
- Proxy server가 다수의 api server를 호출하여 -> 부하분산, 가용성 강화

Webhook을 통한 사용자 인증
- 특정 이벤트가 발생했을 때 다른 서비스에 알림을 보낼 수 있는 기능
- 인증 요청 이벤트 발생 -> api server가 이벤트를 Webhook server로 보내며 처리 요청
- api server가 TokenReview라는 json 오브젝트를 만들어 보내는 것임
- Webhook server는 여기에 status 값을 더해 피드백함

OIDC를 활용한 외부 인증 시스템과 연동
- OpenID Connect: 권한허가를 위해 만들어진 OAuth 프로토콜로 만든 인증 레이어임
- IPD(Identity Provider)에 로그인하여 id_token 받음 (JWT-Json Web Token)
- 이 token으로 API server에 인증 요청
- 유효기간이 존재하는 토큰임

일반 유저

Authorization (권한부여, 인가)
 ABAC 속성 기반 접근 제어
- 유저나 그룹별로 접근할 수 있는 속성을 하나의 policy 파일로 관리함
- 속성: apiGroup, namespace, resource
- 라인 하나당 json 형태로 정책 하나씩 설정

RBAC 역할 기반 접근 제어
- 리소스에 대한 접근 권한을 쿠버네티스 리소스로 정의
- Role과 RoleBinding (특정 namespace에 종속)
    - Role: 특정 리소스에 수행할 수 있는 액션에 대한 룰(rules)의 집합
        - 리소스: pod, log, secret, configmap...
        - 액션: get, list, watch, create, delete...
        - role은 특정 namespace에 종속된다
    - RoleBinding
        - 생성한 Role을 특정유저나 그룹에게 부여하는 리소스
        - subjects, roleRef
- ClusterRole과 ClusterRoleBinding
    - 특정 namespace에 종속되지 않는 cluster-wide resource

Webhook을 이용한 권한 체크
- 인가 부분을 웹훅서버에 전달하고, 인가를 위임
- api server가 SubjectAccessReview 보냄(json object)

6. 리소스 제한(limitation)
Kube-scheduler

CPU
0.1은 1.0의 1/10 (1=1Core)
0.1은 100m
m은 밀리코어, 밀리Cpu로 발음
최소값은 1m (0.001) - 1/1000

 Ch2. Kubernetes 구축

1. 퍼블릭 클라우드의 쿠버네티스 서비스 사용
관리형 쿠버네티스 서비스들

2. AWS EKS
Elastic Kubernetes Service

순서
VPC: EKS가 배포될 네트워크
IAM, security group: EKS를 사용하기 위한 접근권한
EKS 생성: 마스터 노드 생성, 사용자에게 노출안됨
Worker node 생성: 워커 노드그룹 생성, EC2 인스턴스 사용
EKS 클러스터 연결: Kubeconfig 생성

3. Google GKE




4. Azure AKS


5. NaverCloud Kubernetes



6. 베어메탈에 쿠버네티스 설치하기



7. kubeadm


8. kubespray


9. Cluster-API를 이용한 Kubernetes in Kubernetes

10. [실습] Kubeadm를 통해 Kubernetes 구축하기

project = norse-voice-369104
10.240.0.0/24 - 내부
내부 - 22(ssh}), 6443포트(kube-apiserver가 사용하는 포트), icmp(ping위해)
34.64.93.80 - 외부, 로드밸런서

controller-0의 정보 10.24.0.10 / 34.64.78.30
controller-1의 정보  10.24.0.11 / 34.64.181.203
controller-2의 정보  10.24.0.12 / 34.64.137.34


gcloud init
gcloud config list
(이 정보 알 수 있음) 

네트워크 만들기
gcloud compute networks create fastcampus-k8s --subnet-mode custom

서브네트워크 만들기
gcloud compute networks subnets create k8s-nodes \
--network fastcampus-k8s \
--range 10.240.0.0/24

방화벽 설정
내부 - 통신 가능하도록 설정
gcloud compute firewall-rules create fastcampus-k8s-allow-internal --allow tcp,udp,icmp,ipip --network fastcampus-k8s --source-ranges 10.240.0.0/24

외부 - 통신 가능하도록 설정
gcloud compute firewall-rules create fastcampus-k8s-allow-external \
--allow tcp:22,tcp:6443,icmp \
--network fastcampus-k8s \
--source-ranges 0.0.0.0/0

퍼블릭 IP 설정
로드 밸런싱용 외부 IP임 (이곳에서 여러 API 서버로 뿌려줌)
gcloud compute addresses list
gcloud compute addresses create fastcampus-k8s

클라우드 NAT 설정
내부에서 외부로 연결 가능하게 함
그렇게 하기 위해 라우터 만들어 주어야 함
라우터 먼저 만들기
gcloud compute routers create k8s-router \
 --network fastcampus-k8s \
 --region asia-northeast3

NAT 설정 추가
gcloud compute routers nats create k8s-nat \
    --router-region asia-northeast3 \
    --router k8s-router \
    --nat-all-subnet-ip-ranges \
    --auto-allocate-nat-external-ips

여기까지가 쿠버네트스 클러스터를 구글 클라우드 위에 설치하기 위한 사전 설정임

------
tmux 사용법

sudo apt install tmux
tmux

상하로 pane불할하기 ctrl +b 하고 “
pane끼리 이동하기 ctrl + b하고 o

열려있는 pane에서 명령어 동시 입력하기
<Ctrl-B>, :
setw synchronize-panes on


윈도우 생성 (ctrl + b) c
윈도우 이동 (ctrl + b) 숫자
다음 윈도우 이동 (ctrl +b) n
이전 윈도우 이동 (ctrl +b) p

ctrl+d - pane 삭제, 종료됨


----------
vi 사용법

vi
/찾을 문자열 (아래로 검색)
?찾을 문자열 (위로 검색)
n or N (다음 문자열, 이전 문자열 검색)

------


11. [실습] Master Node 구축

*컨트롤 플레인 노드 역할을 하게 될 인스턴스 만들어야 함 - 예제는 3대 구축
for i in 0 1 2; do
  gcloud compute instances create controller-${i} \
    --async \
    --boot-disk-size 200GB \
    --can-ip-forward \
    --image-family ubuntu-2004-lts \
    --image-project ubuntu-os-cloud \
    --machine-type e2-standard-2 \
    --private-network-ip 10.240.0.1${i} \
    --scopes compute-rw,storage-ro,service-management,service-control,logging-write,monitoring \
    --subnet k8s-nodes \
    --tags fastcampus-k8s,controller
done

controller-1, 2도 만들기, 네트워크 IP는 끝자리  11, 12로 바꾸기
* controller-0은 인스턴스를 e2-standard-4로 만드는 것이 좋음(추후에 prometheus설치시 cpu 성능 부족할 수 있어서)

gcloud compute  instances list

*만든 노드에 kubeadm 설치하기
gcloud compute ssh controller-0 (1, 2번도 동일)
처음에는 보안키 만드니까
exit -> 다시 접속

OS  설정 - 패키지 매니저 업데이트
sudo apt update

필요 패키지 설치
sudo apt -y install apt-transport-https 

구글 클라우드를 사용하기 위한 인증키 받아오기
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

쿠버네티스에서 제공하는 우분투용 저장소 설치
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

다시 저장소 업데이트?
sudo apt update (반복실행 or 나갔다 들어오면 바로 업데이트 에러 안남)

apt 통해 필수 바이너리 설치
sudo apt -y install vim git curl wget kubelet kubeadm kubectl

패키지 홀드할 수 있음(강제 업데이트 등 방지)
sudo apt-mark hold kubelet kubeadm kubectl

버전 체크
kubectl version --client && kubeadm version

cf> 최신 버전 아닌, 원하는 버전 설치하기
sudo apt -y install kubelet=1.21.11-00 kubectl=1.21.11-00 kubeadm=1.21.11-00

이제 쿠버네티스 설치 전 해야 할 설정들
*메모리 스왑
fstab에 관련된 스왑 설정을 삭제
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

스왑 관련된 명령 실행
sudo swapoff -a

 *컨테이너 런타임 절치
(이번 실습은 docker아닌, container d 설치)
sudo tee /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF

개별적으로 노드 실행
sudo modprobe overlay
sudo modprobe br_netfilter

*쿠버네티스에서 필요한 sysctl 설정하기
ipforwarding관련 세팅
sudo tee /etc/sysctl.d/kubernetes.conf<<EOF
net.bridge.bridge-nf.call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

최신화시키기
sudo sysctl --system

containerd설치
사전 패키지 설치
sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates

container 설치에 필요한 공개키 다운도르
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

apt 저장소 추가
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

저장소 추가 후 apt update (최신화)
sudo apt update

containerd 인스톨
sudo apt install -y containerd.io

containerd 설정
루트유저로 접속
sudo su -

 
기본 컨피그 파일 만들기
containerd config default>/etc/containerd/config.toml
안되면 containerd config default > /etc/containerd/config.toml

시스템 데몬 실행
sudo systemctl restart containerd
sudo systemctl enable containerd

설치확인
systemctl status containerd

containerd가 cgroup설정 사용할 수 있는 환경 만들기
vi /etc/containerd/config.toml
systemdCgroup - false 를 true로 바꾸어 주기

container 재시작
sudo systemctl restart containerd
status로 상태 확인하기

쿠버네티스가 사용할 클라우드 자원 configuration 해주기
(밑의 project-id 모르면 gcloud config list로 조회)

cat << EOF | sudo tee /etc/kubernetes/cloud-config
[Global]
project-id = norse-voice-369104 
EOF

*노드 나와서 구글 클라우드 설정 해주기
위의 작업을 0-2번 다 해주고

구글 클라우드 설정하기 (mac terminal에서)
로드밸런서가 사용할 방화벽 만들기
gcloud compute firewall-rules create fw-allow-network-lb-health-checks \
--network=fastcampus-k8s \
--action=ALLOW \
   --direction=INGRESS \
--source-ranges=35.191.0.0/16,209.85.152.0/22,209.85.204.0/22 \
--target-tags=allow-network-lb-health-checks \
--rules=tcp
 
로드밸런서에 컨트롤러 노드 등록하기
gcloud compute instance-groups unmanaged create k8s-master \
--zone=asia-northeast3-a

gcloud compute instance-groups unmanaged add-instances k8s-master \
--zone=asia-northeast3-a \
--instances=controller-0 
(kubeadm은 최초 마스터 노드를 실행시킨다. 추가적으로 다른 마스터 노드들은 추후에 조인시키는 것임)

로드밸런서가 kube-api서버가 정상적으로 돌아가는지 health check 룰 설정
gcloud compute health-checks create https k8s-controller-hc --check-interval=5 \
--enable-logging \
--request-path=/healthz \
--port=6443 \
--region=asia-northeast3

백엔드 서비스 만들기
gcloud compute backend-services create k8s-service \
--protocol TCP \
--health-checks k8s-controller-hc \
--health-checks-region asia-northeast3
 
백엔드에 아까 만든 인스턴스 그룹을 추가
gcloud compute backend-services add-backend k8s-service \
--instance-group k8s-master \
--instance-group-zone asia-northeast3-a \
--region asia-northeast3

로드밸런서가 해당 인스턴스들을 로드밸런싱을 할 수 있도록 포워드 룰 설정
gcloud compute forwarding-rules create k8s-forwarding-rule \
--load-balancing-scheme external \
--region asia-northeast3 \
--ports 6443 \
--address fastcampus-k8s \
--backend-service k8s-service

kubeadm 실행하기
controller-0에 다시 접속

cat << EOF > kubeadmcfg.yaml
apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
nodeRegistration:
  criSocket: "/run/containerd/containerd.sock"
  kubeletExtraArgs:
    cloud-provider: "gce"
    cloud-config: "/etc/kubernetes/cloud-config"
    cgroup-driver: "systemd"
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
apiServer:
  extraArgs:
    cloud-provider: "gce"
    cloud-config: "/etc/kubernetes/cloud-config"
  extraVolumes:
  - name: cloud
    hostPath: "/etc/kubernetes/cloud-config"
    mountPath: "/etc/kubernetes/cloud-config"
controllerManager:
  extraArgs:
    cloud-provider: "gce"
    cloud-config: "/etc/kubernetes/cloud-config"
  extraVolumes:
  - name: cloud
    hostPath: "/etc/kubernetes/cloud-config"
    mountPath: "/etc/kubernetes/cloud-config"
networking:
  podSubnet: "192.168.0.0/16"
  serviceSubnet: "10.32.0.0/24"
controlPlaneEndpoint: "34.64.93.80:6443"
---
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
cgroupDriver: systemd
serverTLSBootstrap: true
EOF

***controlPlaneEndpoint:에  gcloud compute addresses list에서 외부IP찾아서 넣어주기

sudo kubeadm init --upload-certs --config kubeadmcfg.yaml
kube apiserver, kube controller-manager, kube scheduler, 상태 저장소인 etcd까지 자동 생성해줌 
   
설치시 설명에 나온 다음 명령어 실행해 주기
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

kubectl get nodes 명령으로 제대로 설치되었는지 확인해 보기

*나머지 노드들 추가해 주기
추가할 노드들에서 명령어 실행해 주어야 함
(master node, work node, 명령어로 선택가능)

You can now join any number of the control-plane node running the following command on each as root:

sudo kubeadm join 34.64.93.80:6443 --token xy6y87.b9rb07qq42imuq0w --discovery-token-ca-cert-hash sha256:246848af0bb2424c7e1b433f6b68964a1b271809a8a937fa235b257066f9adb7
--control-plane --certificate-key 888deaded9a6754f43955ecdc93c317df9ce383f38f7ca3643b6151eb0a47e17


Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 34.64.93.80:6443 --token xy6y87.b9rb07qq42imuq0w \
--discovery-token-ca-cert-hash sha256:246848af0bb2424c7e1b433f6b68964a1b271809a8a937fa235b257066f9adb7 








sudo -i (이것도 루트 접속임) = sudo su -


<워커노드 만들기>
vm생성
for i in 0 1 2; do
  gcloud compute instances create worker-${i} \
    --async \
    --boot-disk-size 200GB \
    --can-ip-forward \
    --image-family ubuntu-2004-lts \
    --image-project ubuntu-os-cloud \
    --machine-type e2-standard-2 \
    --metadata pod-cidr=10.200.${i}.0/24 \
    --private-network-ip 10.240.0.2${i} \
    --scopes compute-rw,storage-ro,service-management,service-control,logging-write,monitoring \
    --subnet k8s-nodes \
    --tags fastcampus-k8s,worker
done

gcloud compute ssh controller-0~2

OS 설정
sudo apt update
sudo apt -y install curl apt-transport-https
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt update
sudo apt -y install vim git curl wget kubelet kubeadm kubectl
(버전 다르게는 sudo apt -y install kubelet=1.21.11-00 kubectl=1.21.11-00 kubeadm=1.21.11-00)

sudo apt-mark hold kubelet kubeadm kubectl

kubectl version --client && kubeadm version

sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
sudo swapoff -a

containerd 설치
sudo tee /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

sudo tee /etc/sysctl.d/kubernetes.conf<<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF


sudo sysctl --system

containerd 설치
sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates
 
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

레파지토리 추가
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

sudo apt update
sudo apt install -y containerd.io

sudo su -
mkdir -p /etc/containerd
containerd config default>/etc/containerd/config.toml

sudo systemctl restart containerd
sudo systemctl enable containerd
systemctl status  containerd

containerd의 cgroup 설정
/etc/containerd/config.toml에서 SystemdCgroup을 true로 설정
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  ...
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
    SystemdCgroup = true

vi /etc/containerd/config.toml 

systemctl status  containerd

sudo systemctl restart containerd

kubelet 활성화
sudo systemctl enable kubelet

join

CSR 승인 (controller-0에서)
kubectl get po -A
kubectl logs -n kube-system kube-apiserver-controller-0
인증서 활성화 안했기 때문에 에러 남
kubectl get csr로 보면 대부분 pending상태인 것 볼 수 있음

kubectl certificate approve
kubectl get -o wide csr|grep Pen|awk '{print "kubectl certificate approve "$1}'|bash

CNI 설치
NotReady의 이유
kubectl describe nodde controller-0

curl https://projectcalico.docs.tigera.io/manifests/calico.yaml -O
kubectl apply -f calico.yaml
kubectl get po -A
kubectl get node



?
kubectl config view

cf
https://github.com/Jaesang/fastcampus_kubernetes/tree/main/kubernetes/hands-on

GCPD CSI 설치
사이트
https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver/blob/master/docs/kubernetes/user-guides/driver-install.md

golang 설치
wget https://go.dev/dl/go1.18.linux-amd64.tar.gz
sudo rm -rf /usr/local/go && sudo tar -C /usr/local -xzf go1.18.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin
mkdir -p go/bin
mkdir go/pkg
mkdir go/src
export GOPATH=$HOME/go

gcloud 설치 (이미 있음, google vm이니까, 없을 때는 설치)
echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
sudo apt-get update && sudo apt-get install google-cloud-cli

gcloud 설정
google cloud에 적합한 권한 설정
gcloud init하면 되는데, local환경이 아니라 vm환경이라 아래 옵션 사용
gcloud init --no-browser --console-only

lob in with a new account 선택

인증위해 주어진 링크 웹브라우저에서 실행하기 (매번 달라질듯?)

승인코드 복사해서 붙여넣기

(이거 안해줘도 clone하면 자동 생성 되는 듯)
mkdir ~/go
export GOPATH=$HOME/go
mkdir -p go/bin
mkdir go/pkg
mkdir go/src

CSI 다운로드
git clone https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver $GOPATH/src/sigs.k8s.io/gcp-compute-persistent-disk-csi-driver

create new one 선택?

export PROJECT=norse-voice-369104
export GCE_PD_SA_NAME=my-gce-pd-csi-sa
export GCE_PD_SA_DIR=~/gce_pd_sa_dir
export ENABLE_KMS=false

mkdir ~/gce_pd_sa_dir

./deploy/setup-project.sh

cat /home/Spike/gce_pd_sa_dir/cloud-sa.json

CSI 설치 (deploy 관련 드라이버 설치)
export GCE_PD_DRIVER_VERSION=stable-master
./deploy/kubernetes/deploy-driver.sh

kubectl get ns 로 확인
kubectl get po -n gce-pd-csi-driver

ls examples/kubernetes/
kubectl get storageclass - 아직은 아무 것도 없음

스토리지클래스 생성
kubectl apply -f examples/kubernetes/demo-zonal-sc.yaml 
kubectl get sc

볼륨 생성
kubectl apply -f examples/kubernetes/demo-pod.yaml 
kubectl get pvc (bound로 나오면 정상)
kubectl describe po web-server

(cf. GCPD CSI드라이버를 기본(default) 스토리지클래스로 설정하려면
kubectl patch storageclass csi-gce-pd -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class": "true"}}}'


Ch4. Kubernetes 관리
01. 쿠버네티스 모니터링

02. 리소스 메트릭과 완전한 메트릭

03. [실습] metrics-server를 활용한 리소스 모니터링
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes" |jq '.'

kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes/worker-2" |jq '.'

kubectl get --raw "/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods" |jq '.'

kubectl get --raw "/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-scheduler-controller-2" |jq '.'


kubectl get hpa


04. Promethus와 Grafana

Promethus장점
모든 서비스에 대한 지속적인 관리
알림



Promethus 설치 
https://github.com/prometheus-operator/kube-prometheus

(controller-0에서 실행)
git clone https://github.com/prometheus-operator/kube-prometheus.git -b release-0.10
or
git clone https://github.com/prometheus-operator/kube-prometheus.git

ls manifests -l
ls manifests/setup -l

kubectl create -f ./manifests/setup/
kubectl create -f ./manifests/

kubectl get pod -n monitoring
kubectl get svc -n monitoring

외부 접속 가능하게 Loadbalance 설정 추가하기
type: LoadBalancer (selector 라인에 맞춰)

 
vi manifests/prometheus-service.yaml
vi manifests/alertmanager-service.yaml


kubectl apply -f 로 세 yaml 적용해 주기

prometheus에 웹브라우저로 접속해 보기
34.64.32.45:9090
34.64.186.194:9093
34.64.147.249:3000





